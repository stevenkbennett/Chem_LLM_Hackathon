{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Information\n",
    "----------------------\n",
    "**Created By:**   Steven Bennett, Friedrich Hastedt\n",
    "\n",
    "This is an example notebook for task 1. The goal of task 1 is to develop a model that is able to perform single-step retrosynthesis prediction. Specifically, the goal of the model is given a target molecule, the model should be able to predict a single reaction step that will produce the target molecule from one or more reagents.\n",
    "The model will be evaluated in 3 different ways:\n",
    "\n",
    "1. Top-10 score: The percentage the reactants from the test set appear in the top-10 predictions proposed by the model.\n",
    "2. Duplicates: The percentage of duplicated reactants in the top-10 predictions proposed by the model. (The actual score is 1 - the percentage of duplicated reactants to maximise the score.)\n",
    "3. Invalidity: The percentage of invalid predictions in the top-10 predictions proposed by the model.\n",
    "(The actual score is 1 - the percentage of invalid predictions to maximise the score.)\n",
    "\n",
    "From these evaluation metrics, we will provide a final score for each model, using a weighted average of the different metrics. The final score will be used to rank each team on the GitHub leaderboard.\n",
    "\n",
    "\n",
    "## Notebook Contents\n",
    "----------------------\n",
    "\n",
    "In this notebook, we will show an example of using a pre-trained model as a starting point to generate the output file for submission to the competition. The notebook will cover the following steps:\n",
    "\n",
    "1. Loading the pre-trained model, and performing data pre-processing steps\n",
    "2. Generating predictions on the held-out test set and saving the output file\n",
    "\n",
    "You are free to experiment with as many different models as you like, and this notebook only serves as an example of how to get started. You are free to use any other models that you like, including using ChatGPT to make prediction, and you are free to use any other data that you like. \n",
    "The only requirement is that the test set data is used to generate the output file for the submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below only needs to be executed if you are running the notebook on a local computer\n",
    "\n",
    "Before executing the notebook, please ensure that you have installed the correct dependencies. It is highly recommended to create a new Anaconda environment specifically for this task. The dependencies can be installed using the following command:\n",
    "\n",
    "```conda env create -f conda_env.yml```\n",
    "\n",
    "The kernel for the notebook can then be instaleld using the following command:\n",
    "    \n",
    "```python -m ipykernel install --user --name chem_llm_hackathon --display-name \"chem_llm_hackathon\"```\n",
    "\n",
    "This will ensure the kernel is locatable by the Jupyter notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute these functions to download the model and data\n",
    "!wget -O 'USPTO50_model_step_500000.pt' 'https://www.dropbox.com/s/fm0cyzxwmxqy7c5/USPTO50_model_step_500000.pt?dl=0'\n",
    "!wget -O 'USPTO50USPTO50.train.0.pt' 'https://www.dropbox.com/scl/fi/ssalt02e4ae0uggnqq5bn/USPTO50USPTO50.train.0.pt?rlkey=0t151ep0b2b59gng61dpgkxt9&dl=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_model import Model\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdChemReactions as Reactions\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a checkpoint file, from the MolecularTransformer paper (https://pubs.acs.org/doi/10.1021/acscentsci.9b00576), which has been trained for half-million epochs. For using this model, we have included some initial code for loading the model and generating predictions. You are free to use this model as initial stating point for an initial set of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a prediction, call the *.predict()* method on the model. The arguments to the method are as follows: \n",
    "\n",
    "1. **source_path**: <br> \n",
    "Do not modify this, this is the directory to the test molecules.\n",
    "\n",
    "2. **num_predictions / beam_size**: <br> \n",
    "beam_size is used by the model to generate more than 1 prediction whereas num_predictions handles the number of predictions returned to the user. Please ensure that those are equal to one another. The scoring will be performed on the first 10 predictions, however feel free to return more than 10 predictions and re-rank them to improve your results.\n",
    "\n",
    "\n",
    "3. **batch_size**: <br>\n",
    "The number of examples fed to the model during one gradient update step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = Model(\n",
    "    model_path=\"USPTO50_model_step_500000.pt\", \n",
    "    gpu=0 # Set GPU index to the number of the GPU you want to use. -1 for CPU and 0 for GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets evaluate the performance of this model on the validation set using the three evaluation metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, perform predictions using the small validation set\n",
    "\n",
    "results = model.predict(\n",
    "    source_path='Data/val_input_small.txt',\n",
    "    num_predictions=10,\n",
    "    batch_size=100,\n",
    "    beam_size=10\n",
    ")\n",
    "\n",
    "# Create some bad results to test the evaluator\n",
    "\n",
    "# Lots of invalid SMILES\n",
    "\n",
    "results_invalid = {\n",
    "    r: [i[:-2] for i in k] for r, k in results.items() \n",
    "}\n",
    "\n",
    "# Lots of duplicates\n",
    "\n",
    "results_duplicates = {\n",
    "    r: [k[0] for i in range(10)] for r, k in results.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import Duplicates, InvalidSMILES, TopK\n",
    "\n",
    "from rdkit import RDLogger\n",
    "# Silence RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "evaluators = [Duplicates(), InvalidSMILES(), TopK(k=10, test_path='Data/val_output_small.txt')]\n",
    "\n",
    "res_names = [\"Duplicate Result\", \"Invalid Results\", \"Standard Results\"]\n",
    "# Evaluate the model\n",
    "print(\"\\n------------------\\n\")\n",
    "for i, res in enumerate([results_duplicates, results_invalid, results]):\n",
    "    print(res_names[i])\n",
    "    for evaluator in evaluators:\n",
    "        print(evaluator.__class__.__name__, round(evaluator(res), 2))\n",
    "    print(\"\\n------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have provided an example of performing the predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions on the test set using a checkpointed model\n",
    "# Some pararameters to be changed could be the beam size, which specifies the number of molecules that are decoded form the model.\n",
    "# This will load the test input file and make 250 prediction using the test file. \n",
    "results = model.predict(\n",
    "    source_path='Data/test_input.txt',\n",
    "    num_predictions=10,\n",
    "    batch_size=100,\n",
    "    beam_size=10\n",
    ")\n",
    "\n",
    "# Extracitng the SMILES strings of all the targets - These are the targets to have the model predict the reactants of\n",
    "with open(\"Data/test_input.txt\", \"r\") as f:\n",
    "    targets = f.read().replace(\" \", \"\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should be a dictionary of the form:\n",
    "    ```{\n",
    "        product_smiles: [reactant_smiles_1_prediction, reactant_smiles_2_prediction, ...]\n",
    "    }\n",
    "    ```\n",
    "For each product there should be 10 different predictions in order to calculate the individual metrics, and the file should be saved as a JSON file with the name ```task1.json```.\n",
    "For submission, the target molecules are listed in the `test_input` folder.\n",
    "The submission file can be created and saved using the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of test set molecules is:\", len(results.keys())) # Ensure this is 250\n",
    "print(\"The number of predictions per molecule is:\", len(results[list(results.keys())[0]])) # Ensure this is 10\n",
    "with open(\"../task1.json\", 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the reactants predicted by the model can be done using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the results\n",
    "for target, reaction in list(results.items()):\n",
    "    rxn_smiles = ''\n",
    "    for reactants in reaction:\n",
    "        for r in reactants.split('.'):\n",
    "            rxn_smiles += r\n",
    "            if r != reactants[-1]:\n",
    "                rxn_smiles += '.'\n",
    "        rxn_smiles += '>>' + target\n",
    "        try: \n",
    "            rxn = Reactions.ReactionFromSmarts(rxn_smiles, useSmiles=True)\n",
    "            break\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print an example reaction that was predicted\n",
    "Draw.ReactionToImage(rxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, you have a model that is able to predict the reactants for a given target molecule reasonably well. There are multiple steps that can be taken from this point to improve the model. Some suggestions are:\n",
    "1. Training the model for more epochs (see below cell for an example). The training dataset for the model is provided.\n",
    "2. Using a different model architecture. The MolecularTransformer model is only one of many possible models that can be used for this task. You are free to use any model that you like, including ChatGPT or the OpenAI API interface.\n",
    "Some recommendations of things to try are: IBM RXN (https://rxn.res.ibm.com), ChemCrow (https://github.com/ur-whitelab/chemcrow-public - uses the OpenAI API credits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run more trianing epochs from the original model\n",
    "model.train(\n",
    "    data_path=\"USPTO50USPTO50\",\n",
    "    num_epochs=500001,\n",
    "    gpu_ranks=\"0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Further Resources\n",
    "-----------------------------\n",
    "\n",
    "For students that find the topic of retrosynthesis and LLMs in chemistry interesting, here are some resources that could you started: \n",
    "\n",
    "1. Deep learning in retrosynthesis planning: datasets, models and tools - https://academic.oup.com/bib/article/23/1/bbab391/6375056 (a review article about ML retrosynthesis)\n",
    "2. A smile is all you need: Predicting limiting activity coefficients from SMILES with natural language processing - https://arxiv.org/abs/2206.07048v1 (how SMILES can be used for QSPR)\n",
    "3. An introductory course to Transformer and how to use them with the HuggingFace python package - https://huggingface.co/learn/nlp-course/chapter1/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
